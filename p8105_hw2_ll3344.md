p8105\_hw2\_ll3344
================
Lusha Liang
9/24/2020

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.1     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.0     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

Read in the Mr. Trashwheel dataset.

``` r
trashwheel_df = 
  read_xlsx("./data/trash_wheel.xlsx", 
            sheet = "Mr. Trash Wheel",
            range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read in the precipitation data for 2017 and 2018.

``` r
precip_2018 = 
  read_excel(
    "./data/trash_wheel.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 = 
  read_excel(
    "./data/trash_wheel.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine annual precipitation from 2017 and 2018.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018, precip_2017) 

precip_df = 
  left_join(precip_df, month_df, by = "month")
```

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the harbor, the
trashwheel collects that trash, and stores it in a dumpster. The
trashwheel\_df dataset contains information on year, month, and trash
collected, including some specific kinds of trash (such as sports balls,
plastic bottles, and cigarette butts). There are a total of 344 rows in
our final trashwheel dataset. Additional data sheets include monthly
precipitation data. There are a total of 24 observations in the final
precipitation dataset which includes precipitation in inches by month
for the years 2017 and 2018.

  - The total amount of precipitation in 2018 was 70.33 inches.
  - The median number of sports balls in a dumpster in 2017 was 8.

## Problem 2

Read in the NYC transit data.

``` r
transit_df =
  read_csv("./data/transit.csv") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>%
  mutate(entry = ifelse(entry == "YES", "true", "false"),
         entry = as.logical(entry))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

The NYC transit dataset contains information about characteristics of
entrances and exits of each subway station in NYC. This includes
information on which lines run from each station, whether
entrances/exits are ADA compliant, and so forth. Thus far we have
subsetted a portion of the dataset focusing on subway lines, routes, and
information about entrances. We have also converted entry information
from Yes/No format to logical (True/False). The resulting data set has
1868 rows and 19 columns. Currently the data is not tidy in that the
route variable encompasses both route name and route number.

Since the data contain multiple rows for each distinct station, we will
now determine the number of stations using the distinct function.

``` r
distinct_transit_df =
  transit_df %>% 
  distinct(station_name, .keep_all = TRUE)
```

  - There are 356 distinct stations.
  - Of those stations, 57 are ADA compliant.

Determine what proportion of station entrances/exits without vending
allow entrance.

``` r
without_vending_df = 
  transit_df %>% 
  filter(vending == "NO")

without_vending_entry_df =
  without_vending_df %>%
  filter(entry == "TRUE")
```

  - The number of station entrances/exits without vending that allow
    entrance is 69.
  - The total number of stations entrances/exits without vending is 183.
  - The proportion of station entrances/exits without vending that allow
    entry out of all stations without vending is 0.3770492.

Now we will reformat data so they are tidier\! More explicitly, we will
reoconfigure the route variable to two distinct variables: one that
contains route number and one that contains route name.

``` r
tidy_transit_df = 
  distinct_transit_df %>%
  mutate(across(route1:route11, as.character)) %>%
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    names_prefix = "route",
    values_to = "route_name"
  )
```

48 distinct stations serve the A train.

``` r
a_train_df =
  tidy_transit_df %>%
  filter(route_name == "A")
```

Of the stations that serve the A train, 10 are ADA compliant.

## Problem 3

Read in the FiveThirtyEight data.

``` r
pols_df =
  read_csv("./data/fivethirtyeight/pols-month.csv")
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
unemployment_df =
  read_csv("./data/fivethirtyeight/unemployment.csv")
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

``` r
snp_df =
  read_csv("./data/fivethirtyeight/snp.csv")
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

Clean pols\_month data.

``` r
pols_df = 
  pols_df %>%
  separate(mon, into = c("year", "month", "day"), sep = "-") %>%
  mutate(across(year:day, as.numeric))

pols_df = left_join(pols_df, month_df, by = "month")  

pols_df =
  pols_df %>%
  relocate(year, month_name) %>%
  mutate(president = ifelse(prez_gop == 0, "dem", "gop")) %>%
  arrange(year, month) %>%
  select(-c(month, day, prez_gop, prez_dem)) %>%
  rename(month = month_name)
```

NB: Interestingly, prez\_gop has values of 0 for Democrat and 1 for
Republican/GOP, but also a few values of 2 between August through
December of 1974 which correspond to the transition of the presidency
from Richard Nixon to Gerald Ford following Watergate and Nixon’s
subsequent impeachment. However, since Gerald Ford was a Republican as
well, the above code specifying that any value but “0” in the prez\_gop
column should be coded as “gop” is still correct and produces “gop” in
the months between August through December of 1974.

Clean snp data.

``` r
snp_df = 
  snp_df %>%
  separate(date, into = c("month", "day", "year"), sep = "/") %>%
  mutate(across(month:year, as.numeric))

snp_df = left_join(snp_df, month_df, by = "month")  

snp_df =
  snp_df %>%
  relocate(year, month_name) %>% 
  arrange(year, month) %>%
  select(-c(month, day)) %>%
  rename(month = month_name)
```

Tidy the unemployment data.

``` r
unemployment_df = 
  unemployment_df %>%
  rename(year = Year, January = Jan, February = Feb, March = Mar, April = Apr, June = Jun, July = Jul,
         August = Aug, September = Sep, October = Oct, November = Nov, December = Dec) %>%
  pivot_longer(
    January:December,
    names_to = "month",
    values_to = "unemployment"
  ) 
```

Join snp with pols.

``` r
snp_pols_df = left_join(pols_df, snp_df, by = c("month", "year")) 
```

Join unemployment with the
result.

``` r
complete_df = left_join(snp_pols_df, unemployment_df, by =c("month", "year"))
```

This final dataset now contains the pols, snp, and unemployment
datasets, grouped by month and year.

  - The pols dataset contains information from January 1947 to June 2015
    related to the number of national politicians who are democratic or
    republican at any given time.
  - The snp dataset contains the closing values of the S\&P from January
    1950 to July 2015.
  - The unemployment dataset contains the monthly unemployment
    percentages from January 1948 to June 2015.
  - The final dataset has a total of 822 observations and 11 variables.
  - The final dataset has the same date range as that of the pols
    dataset since we merged subsequent datasets into the pols dataset
    using left join.
  - The variables contained in the final dataset are: year, month,
    gov\_gop, sen\_gop, rep\_gop, gov\_dem, sen\_dem, rep\_dem,
    president, close, unemployment.
